{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e768f1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Ex-5\n",
    "\n",
    "# ===============================\n",
    "# MS-COCO Image Classification + Augmentation + CNN + Faster R-CNN\n",
    "# ===============================\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.models.detection as detection\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# -------------------------------\n",
    "# a. Load the dataset\n",
    "# -------------------------------\n",
    "# Provide paths to the COCO images and annotations\n",
    "coco_root = \"path_to_coco/train2017\"       # Replace with your path\n",
    "coco_annFile = \"path_to_coco/annotations/instances_train2017.json\"\n",
    "\n",
    "transform_basic = transforms.Compose([\n",
    "    transforms.Resize((128, 128)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "coco_dataset = CocoDetection(root=coco_root, annFile=coco_annFile, transform=transform_basic)\n",
    "\n",
    "# -------------------------------\n",
    "# b. Show number of training/testing images\n",
    "# -------------------------------\n",
    "train_size = int(0.8 * len(coco_dataset))\n",
    "test_size = len(coco_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(coco_dataset, [train_size, test_size])\n",
    "\n",
    "print(\"Number of training images:\", len(train_dataset))\n",
    "print(\"Number of testing images:\", len(test_dataset))\n",
    "\n",
    "# -------------------------------\n",
    "# c. Plot some images\n",
    "# -------------------------------\n",
    "def imshow(img_tensor, title=\"\"):\n",
    "    img = img_tensor.permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in range(4):\n",
    "    img, target = train_dataset[i]\n",
    "    plt.subplot(1,4,i+1)\n",
    "    imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# d. Image augmentation â€“ contrast, flipping, rotation\n",
    "# -------------------------------\n",
    "transform_aug = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(contrast=0.5, brightness=0.3),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "augmented_dataset = CocoDetection(root=coco_root, annFile=coco_annFile, transform=transform_aug)\n",
    "aug_train_dataset, aug_test_dataset = random_split(augmented_dataset, [train_size, test_size])\n",
    "\n",
    "# -------------------------------\n",
    "# e. Show number of training/testing images after augmentation\n",
    "# -------------------------------\n",
    "print(\"After augmentation:\")\n",
    "print(\"Training images:\", len(aug_train_dataset))\n",
    "print(\"Testing images:\", len(aug_test_dataset))\n",
    "\n",
    "# -------------------------------\n",
    "# f. Normalize training data\n",
    "# -------------------------------\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform_final = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# g. Build a simple CNN to train images\n",
    "# -------------------------------\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=80):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*32*32, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(aug_train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(aug_test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Model, loss, optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn_model = SimpleCNN(num_classes=80).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# -------------------------------\n",
    "# h. Train CNN\n",
    "# -------------------------------\n",
    "epochs = 2  # Use 2 for demonstration; increase for real training\n",
    "for epoch in range(epochs):\n",
    "    cnn_model.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, targets in train_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        # For classification, select first object category as target\n",
    "        target_labels = torch.tensor([t[0]['category_id'] for t in targets]).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_model(imgs)\n",
    "        loss = criterion(outputs, target_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluate CNN accuracy\n",
    "cnn_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, targets in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        target_labels = torch.tensor([t[0]['category_id'] for t in targets]).to(device)\n",
    "        outputs = cnn_model(imgs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += target_labels.size(0)\n",
    "        correct += (predicted == target_labels).sum().item()\n",
    "print(\"CNN Testing Accuracy: {:.2f}%\".format(100*correct/total))\n",
    "\n",
    "# -------------------------------\n",
    "# j. Build a Faster R-CNN to train images\n",
    "# -------------------------------\n",
    "faster_rcnn = detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "faster_rcnn.to(device)\n",
    "faster_rcnn.train()\n",
    "\n",
    "# Dummy training loop for demonstration (actual training on COCO is heavy)\n",
    "print(\"Faster R-CNN model ready (training on full COCO requires heavy GPU and time).\")\n",
    "\n",
    "# -------------------------------\n",
    "# i/k. Compare accuracy\n",
    "# -------------------------------\n",
    "print(\"Compare training/testing accuracy before and after augmentation manually based on CNN results.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
